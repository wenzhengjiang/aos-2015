\documentclass[a4paper,12pt]{article}
\usepackage{pdfpages,cite,hyperref}
\usepackage{natbib}
\usepackage[top=1in, bottom=1.5in,left=1in, right=1in]{geometry}
\setcounter{tocdepth}{2}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{caption}
\usepackage{fancyhdr}
\usepackage{array}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{tocloft}
\usepackage{setspace}
\linespread{1}
\setlist{nolistsep}
\setlength\cftparskip{8pt}
\setlength\cftbeforesecskip{1pt}
\setlength\cftaftertoctitleskip{2pt}
\bibliographystyle{agsm}
\hypersetup{colorlinks=true,citecolor=blue,linkcolor=blue,filecolor=blue,urlcolor=blue}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\lhead{}
\fancyfoot[LE,RO]{\slshape \rightmark}
\fancyfoot[LO,RE]{\slshape \leftmark}
\lfoot{}
\rfoot{\thepage}
\renewcommand{\footrulewidth}{0.4pt}
\renewcommand{\refname}{Reference List}
\begin{document}
\renewcommand{\headheight}{15pt}
\setlength{\parskip}{\baselineskip}%
\setlength{\parindent}{0pt}%
\pagenumbering{arabic}
\begin{center}
  \vspace*{60mm}
  {\Large \bfseries{AOS Group 3 - SOS Design Documentation}}\\[8mm]
  19$^{th}$ October, 2015\\[20mm]
\end{center}
\newpage
\tableofcontents
\newpage
\section{Overview}
The Simple Operating System, or SOS, performs resource management for
applications running on top of the seL4 Microkernel on ARMv7, specifically the
SABRE Lite i.MX6.  This document describes the design of SOS as implemented by
AOS Group 3.  For each key design choice in the project, it also discusses
benefits and trade-offs of the decision, and possible alternative approaches.
Refer to Doxygen documentation for implementation-specific details and
conventions.

There are 4 distinct problem-areas that have been explored in SOS: Interrupts
and Syscalls, Memory, I/O and Process Management.  Interrupts and Syscalls
requests are essential for all interaction with SOS, and thus offer a solid
starting point for introducing the system architecture from a higher level
perspective.

\section{Interrupts and System Calls}
\subsection{Execution Model}
\subsubsection{Design}
Implemented in: \texttt{/apps/sos/src/main.c}

At its core, SOS uses an event-based model implemented using
\emph{continuations}.  A continuation allows for non-blocking behaviour during
otherwise by blocking in a single-threaded implementation (for example I/O) by
providing a way to preserve execution state.  This allows for a
single-threaded implementation, while preserving many of the performance
characteristics of a multi-threaded implementation.

A continuation is specific to a process and is used to track the current state
of execution.  For each syscall, the requesting process is identified by an
IPC badged with its Process ID (see `Process Management' for details) thus
allowing association between the process and the syscall.  Similarly,
interrupt handlers also are provided with the Process ID should it be
utilising a continuation.  By allowing execution state to be isolated on a
per-process basis, and thus allow execution t restored to preserve

A continuation in SOS is a struct which describes the current execution
context.  The struct has many fields, which include:

\begin{itemize}
\item the original syscall number
\item the number of re-entries into the syscall handler
\item the number of bytes read or written
\end{itemize}

There are two further mechanisms for controlling the flow of execution, which
effectively implement a blocked and ready queue:
\begin{description}
\item[longjmp()] provides a mechanism whereby jumping to the `ipc\_event\_buf'
  can halt execution of the process, where it can later be resumed by a
  callback handler;
\item[add\_ready\_proc()] provides a `ready queue', where a process can be
  flagged as ready by a callback handler, by this function to add the process
  to the queue
\end{description}

At the completion of a syscall, the function
\texttt{syscall\_end\_continuation()} is used to reply to the client in a
consistent manner, ensuring that all execution state is released and reset
appropriately.  The caller to syscall\_end\_continuation indicates the process
to reply to, the return code, and whether or not the syscall was successful.

\subsubsection{TODO Discussion}
TODO: Talk about threads and event-based models

The design of continuation is conceptually simple, and allows for
type-checking at compile-time, which affords some correctness guarantees.
However, this struct becomes exceedingly large as more behaviours are added to
SOS, each of which may depend on and need to extend upon the state already
stored in the continuation.  As this is a per-process structure, it thus
requires an additional frame to be allocated for every process running on the
system, and should more functionality be added to SOS, may require multiple
frames to be allocated causing concerns over contiguous allocation of the
memory backing the structure.

A more scalable approach would be to implement the continuation as an array or
hash table, whereby 32-bit values could be accessed given a key.  The
implication of this is that compile-time type-checking is lost, and that
accesses will often need to be cast.

This may seem a preferable for the reason of scalability, however static
analysis becomes increasingly valuable for offering correctness guarantees as
an Operating System grows.  For this reason it was deemed an inferior approach
to the single, large continuation structure given the scope of the project.

Yet more sophisticated data structures could also be used, which are amenable
to both static analysis, and better scalability, though the added complexity
of managing these data structures exceeded the benefits for the current
incarnation of SOS.

\subsection{System Calls}
Implemented in: \texttt{/apps/sos/src/handler.c}, \texttt{/apps/sos/src/syscall.c}

\subsubsection{Design}
As this is a continuation-based model, each syscall is implemented in two
parts: a setup handler, and an execution handler.

The setup handler is called once, at the beginning of a syscall and before the
execution handler is invoked.  This allows a single, consistent means of
storing any arguments provided via IPC within the continuation, so that they
may be available to the execution handler.

The syscall dispatch is respresented as a matrix, whereby the number of
implemented syscalls form the `rows', and function pointers to the setup and
execution handlers form the `columns'.  This gives simple and constant-time
access to the syscalls implemented within SOS: the syscall lookup is an index
into the array based on the syscall number, and the handler to be executed is
also an index.

A dispatching funcnion, \texttt{handle\_syscall()} executes the setup handler
should for the desired syscall (should one be defined), storing the fact that
this has been executed in the continuation.  The dispatcher will then invoke
the execution handler for that syscall.

Should the execution of a syscall handler result in an operation which would
otherwise be blocking, execution will return to the syscall loop until an
interrupt occurs based on the completion of the event.  Refer to the previous
section for details.

During the execution of a system call, three functions are used to capture and
access state:
\begin{description}
\item[current\_process] The process which invoked the current system call.
\item[set\_current\_process] Set the current process based on a Process ID (see
  `Process Management' for details)
\item[effective\_process] The process which SOS is acting on behalf of.  This
  is usually identical to current\_process(), with the exception being spawning
  a child process.  It is defined in terms of the current process.
\end{description}
At the completion of a syscall, the state of the process' continuation is
reset.

\subsubsection{TODO Discussion}
TODO: Work out what the scope of this section is/should be and then discuss.

\subsection{Timer Interrupts}
Implemented in: \texttt{/libs/libclock/src/clock.c}

\subsubsection{Design}
The timer interrupt was implemented using the GPT timer on the SABRE.

The GPT timer allows multiple Output Compare Registers to be set
simultaneously, and thus affords the ability to support two different types of
interrupts.

\begin{enumerate}
\item Regular 100ms kernel tick
\item Timed callback events
\end{enumerate}

Both timed callbacks and kernel tick callbacks are exposed via an interface
for registering callback functions when these events occur.

All kernel tick callbacks are called with each kernel tick.  Thus a developer
needs to be aware of the performance characteristics of the tick handler being
registered, and should ensure that the worst-case execution time is minimised.

Timed callbacks are called after a timeout expires.  This is implemented by
ensuring that all registrations are ordered at registration-time, and setting
the corresponding Output Compare Register to the next event in the queue.  The
next event in the queue is determined through a search, where overflow is
accounted for by searching for the event such that the difference between the
current time, and the event time is minimal.

Timed callbacks are removed after being fired and are used to implement the
\texttt{sleep} syscall.  As kernel tick events satisfy different semantics to
timed callback events in the implementation, they are distinguished in the
interface.

\subsubsection{TODO Discussion}
Alternatively the EPIT timer could have been used to implement this
functionality.  Both EPIT and GPT timers on the Sabre have a very similar
interface, and both could equally have been used.  However it was elected that
the GPT is slightly simpler and fulfills all requirements.

TODO: Discuss perf characteristics. Linear registration, linear search.  We
could do better.  Tick registration is linear: again, could do better.

\section{System Memory}
\subsection{Frame Table}
Implemented in: \texttt{/apps/sos/src/frametable.c}
\subsubsection{Design}
The frame table is the representation of physical memory. This memory is
mapped by applications and also used by SOSH.  Only frames are represented by
the frametable, with other datatypes residing elsewhere in the system.

The frame table is an array of structs, where each struct contains the details
specific to the frame (namely, its address and CPtr), as well as a pointer to
the next element.  When SOS bootstraps, all elements of the array are
allocated, and the free pointer chains each node to its successor.

This structure serves as a list of free frames: as frames are allocated, they
are taken from the head of the list, and as they are freed, they are returned
to the head of the list.  Thus giving a O(1) performance for allocation and
deallocation of frames.  Similarly, as the structure is an array, it also
offers O(1) lookup as the address can be transformed in to an index into the
array trivially.

\subsubsection{TODO Discussion}
We could also have represented other datatypes within the `frame table' and
provided a mapping back to them, though the vast majority of typed memory in
the system is typed as frames, and so the added complexity of managing other
datatypes in the frame table outweighs the minimal benefit it offers.  Instead
memory of types other than \texttt{seL4\_ARM\_SmallPageObject} is stored
explictly in other data structures.

TODO: Comment on impact at bootstrap time and memory consumption due to
up-front allocation.

\subsection{Swap File}
Implemented in: \texttt{/apps/sos/src/frametable.c}

\subsubsection{Design}
When the system encounters contention for the available physical memory
resources, some memory may be swapped to disk.  The data structure which
underpins the swap file is similar to that which underpins the frame table: an
array whose free nodes form a linked list, and as such offers the same
performance characteristics as the frame table.

When reading data from the swap file, or otherwise freeing it, the swap file
is not altered.

The swap structure also features a checksum field to protect against altered
or corrupted data from being read-in from disk.

\subsubsection{TODO Discussion}
The current checksum implementation is a summation of the character values of
the file, and so does not protect against transposition or malicious
alteration.  This could be addressed using a more sophisticated checksumming
algorithm.

\section{Process Management}
\subsection{Page Table}
Implemented in: \texttt{/apps/sos/src/addrspace.c}

\subsubsection{Design}
SOS implements a two-level page table within a process' address space.  The
page table divides the virtual address as follows:

TODO: INSERT DIAGRAM

This scheme allows each the Page Directory and the second level of the Page
Table to address 1024 4-byte entries within one 4096-byte frame: each 4-byte
entry is a pointer to a Page Table Entry.

A Page Table Entry (PTE) stores the frame address and page cap corresponding
to the virtual address.  As only 20 bits of the frame address are actually
used, the lower 12 bits in the PTE are available to be reused for other
purposes.  Currently, 3 of these lower-most bits are used to provide flags
indicating: whether the page data is stored on-disk, whether the page is
pinned, and whether it has been referenced.  (See `Page Replacement' for
details.)

This structure allows for efficient lookup: the upper 10 most bits index into
the Page Directory, the next upper 10-most bits index in to the second level
of the Page Table.

For processes running upon the seL4 Microkernel efficiently, seL4 exposes its
own Page Table implementation.  To manage this, the capability for the seL4
Page Directory is stored in the process' Address Space, and the capability to
each Page Table stored in a Linked List.

The linked list is used as the size of a seL4 Page Directory and seL4 Page
Table are 12 and 8 bits respectively, and thus do not map cleanly in to the
SOS Page Table design.  However the data stored in the linked list never need
be accessed explicitly, and exists only for the purpose of releasing the
resource.  A linked list provides constant-time insertion while providing a
simple design at the time of releasing the resources.

\subsubsection{TODO Discussion}
Varying from seL4 implementation: 8/12
Why we did it
How we accounted for implications of that.

\subsection{Page Replacement}
\subsubsection{Design}
SOS implements a second-chance local page replacement algorithm, which takes
place over a number of steps, and occurs in the event that there are isn't any
frames available in the frame table to allocate to a process.

\begin{enumerate}
\item Select the process from which to evict a page.
\item Select a page from that process using a second chance eviction model.
\item Write the page to the swap file.
\end{enumerate}

Selecting the process to evict from is based on a threshold applied across all
process: whether the process exceeds the average number of `evictable' pages
across all processes.  The first process identified which satisfies this
requirement is selected for eviction, or if there isn't any process satisfying
this requirement, the page is evicted from the process which SOS is acting on
behalf of.

In order to guarantee fairness of the system, the process for which eviction
takes place is tracked, and subsequent selection takes place from the
following process.  Similarly, in order to prevent starvation as a result of
two or more processes competing indefinitely for frames, so that they are able
to make progress while the system is under very high resource constraints, the
algorithm may randomly select the current process for eviction.

The page replacement algorithm uses a circular linked list of pages.  For each
page, if the referenced bit for that page table entry is found to be zero, the
page is selected, otherwise the referenced bit is set to zero and the
algorithm proceeds to the next allocated page.

Pages which are pinned, or already swapped to disk are not considered valid
for selection.  Thus there is the potential that there are no pages in the
process which are valid selection.  In this event, (i.e., the event we iterate
through the loop more than twice), the process which SOS is acting on behalf
of is killed in order to relieve the memory contention.

Once a page has been selected, the contents of the frame are written to the
next available location in the swap file.  During the copy, the PTE is marked
as `pinned', and so is not valid for subsequent selection.  Finally once the
write is complete the page is marked as `swapd', indicating that subsequent
accesses to this page must be read from disk, and use of the corresponding
frame is made available to the process requiring it.

\subsubsection{TODO Discussion}

\subsection{Regions}
Implemented in: \texttt{/apps/sos/src/addrspace.c}, \texttt{/apps/sos/src/handler.c}

\subsubsection{Design}
Regions are implemented as a singly-linked list.  Each region contains start,
end, rights, and an offset for the starting location of that region in the elf
file.

\subsubsection{TODO Discussion}
There is no optimisation on the lookup cost of a region.  This data structure
is searched in a number of cases, but most importantly, in the event of a VM
Fault.  A binary may have as few as 4 segments mapped in to the address space,
and in this instance the searching cost may be acceptable.  However as the
number of regions increases, the performance of the system may be subject to
significant degradation.

A better approach may be... TODO

\subsection{Page Faults}
Implemented in: \texttt{/apps/sos/src/handler.c}

\subsubsection{Design}
Page faults within SOS occur in a number of circumstances:

\begin{itemize}
\item for lazy-loading data in from an ELF binary;
\item faulting-in new pages within the heap or stack, and
\item when the process attempts to read data, which has been paged to disk, back into memory;
\item as a means of setting the frame referenced bit for second chance replacement
\end{itemize}

In the event a page corresponding to a virtual address has not been created
within a processes address space when it faults, a new page will be created
dynamically.  When this occurs the corresponding region is used to determine
whether any data should subsequently be loaded in to that page.  This is
indicated by an elf file offset being defined for the corresponding region.
Therefore in this event content for code and data segments will be loaded from
the ELF binary, while zeroed pages will be allocated for the stack and heap as
the process faults within those regions.

Data paged to disk will be indicated by the `swapd' bit in the corresponding
PTE.  In the event a fault occurs on a page with this bit set, the address
(which corresponds to an offset within the swap file) will be used to read in
the page.  During the read, another page may or may not be evicted depending
on whether physical memory is available to facilitate the replacement.

The final scenario in which page faults will occur is in order to set the
`referenced' bit (`refd') of the page to facilitate second-chance page
replacement.  During the replacement algorithm, pages where the referenced bit
is unset will also be unmapped from the process' address space.  Thus when a
fault occurs on a page where the referenced bit is not set, though it is still
in memory, the referenced bit will be set and the page mapped back in to the
process' address space.

\subsubsection{TODO Discussion}

\subsection{Processes}
Implemented in: \texttt{/apps/sos/src/process.c}, \texttt{/apps/sos/src/elf.c}

\subsubsection{Design}
The design for Process IDs allows for constant-time creation, lookup and
removal, and will reuse process IDs minimally.  This is achieved via an array
of `PID entries', where a PID entry is a double-linked node containing a
process ID and a flag to indicate whether it corresponds to a running process.

Closely related to the use of process IDs is the means by which a process is
identified during a callback.  SOS accounts for potential race conditions by
using a reference to a `callback' structure, which contains the creation time
of the callback, and the PID corresponding to the process which the callback
was created on behalf of.  Given that the creation time of the process is
known, it can be determined whether the process now owning the PID for the
callback is the currently running process; a process starting after the
creation time of the callback cannot own the callback, and thus the callback
is discarded.

\subsubsection{TODO Discussion}
Neither the PID nor the running flag are strictly required.  A PID could
equally have been derivedb via pointer arithmetic between the beginning of,
and the current index of the table.  Similarly the running flag could be
derived via a lookup into the process table.  However this does afford the
opportunity to verify the correctness of data structure manipulation, and
clarifies the implementation.

\section{I/O}
\subsection{IO Vectors}
Implemented in: \texttt{/apps/sos/src/file.c}

\subsubsection{Design}
An IO Vector is a representation of client or SOS-internal pages, allowing
memory to be mapped for I/O on-demand.

An IO Vector provides the following fields:
\begin{description}
\item[vstart] The starting address of the frame or virtual address (conditional)
\item[sz] The length of the operation to occur.  sz will be set such that the
  operation does not exceed the page given the starting address `vstart'.
\item[next] The following IO Vector node.
\item[sos\_iov\_flag] Flag indicating whether the IO Vector node corresponds to
  a SOS frame, or process virtual address (thereby indicating whether
  address translation is required)
\end{description}

The benefit of the IO Vector is that it allows for otherwise non-contiguous
pages to be treated as though contigous.  It also provides a means for
restarting IO operations, and the IO Vectors needs simply be updated to
reflect the current progress of an operation.

IO Vectors are used to represent most I/O operations in SOS.

\subsubsection{TODO Discussion}
- Current usage means that we may do short IO ops (e.g. 10 bytes to finish
reading a page), even though we could do a large IO op (4k) and write across
IO Vectors simultaneously.

\subsection{Serial Device}
Implemented in: \texttt{/apps/sos/src/serial.c}

\subsubsection{Design}
The serial device implementation satisfies single-reader / multiple-writer
semantics, where the process is only permitted to read should no other process
have the serial device open for reading.  This uses global state (named
`reader\_pid`) within the serial driver, which allows the owning process to be
identified in constant time.

Reads in SOS are buffered, though only the most recent line is preserved; any
subsequent line is discarded.  This provides bounds over the size of the
buffer, while allowing non-blocking behaviour should have already been
provided from the user.

When the read() is invoked by the client, the pages corresponding to that read
are pinned, and subsequently unpinned when the read operation returns to the
caller.  As the buffer is at most 1024 bytes, up to two pages can be pinned
because of this.

The serial driver is initialised at boot-time.

\subsubsection{TODO Discussion}
Storage and use of reader buffer

Discuss the reason for pinning.

\subsection{NFS}
Implemented in: \texttt{/apps/sos/src/sos\_nfs.c}

\subsubsection{Design}
The NFS implementation in SOS relies heavily on callbacks and continuations,
which have been discussed previously.  Prior to spawning a request for which a
subsequent callback is expected, a `callback info' struct will be allocated,
which contains the time the callback was initiated and the process initiating
the callback.  The address of this is used as the token, and uniquely
identifies the context for the callback once the callback is realised.

The PID from the callback is used to set the context for the subsequent
execution, in the same was as the badge for a process' IPC is used to set the
context for a syscall.

Detection of completion of the syscall is handled individually in each
callback.  In the event of error, or completion, the callback is responsible
for triggering an appropriate reply to the client over IPC.

\subsubsection{TODO Discussion}

\subsection{IO Device}
\subsubsection{Design}
An IO device is an abstraction over both block and character devices.  In the
case of SOS, this abstracts both Serial and NFS to create a uniform IO
interface through mapping function pointers to their respective
implementations.

Thus an IO Device provides an interface for all available IO operations over
any driver.  Thus it currently exposes:

\begin{itemize}
\item open
\item close
\item read
\item write
\item getdirent
\item stat
\end{itemize}

For both the serial and NFS drivers.  As the serial driver does not support
some of these operations, those operations are undefined (NULL).

\subsubsection{TODO Discussion}
The IO Device is a light-weight mechanism to abstract access to IO-related
drivers.  An alternative to this would be the implementation of a VFS-like
abstraction.  However, given that the goals of the project were to support a
single, flat filesystem, and a serial device, this was deemed an overly
extravagant abstraction.

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
